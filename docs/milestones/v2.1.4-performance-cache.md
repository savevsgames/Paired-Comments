# Milestone: Performance Cache (v2.1.4)

**Target Release:** December 2025 (1 week)
**Priority:** Medium-High
**Estimated Effort:** 2-3 days
**Dependencies:** None

---

## üìã Overview

Optimize performance for large files (1000+ lines) and many comments (100+ per file) through intelligent caching of AST parse results, comment data, and ghost marker states. Currently, every file open/save triggers full AST parsing and comment loading, which becomes slow at scale.

---

## üéØ Goals

### Primary
- **AST Parse Cache** - Cache VS Code symbol provider results to avoid re-parsing
- **Comment File Cache** - Keep .comments files in memory with LRU eviction
- **Ghost Marker Cache** - Cache marker verification results
- **Incremental Updates** - Only re-parse changed regions of files

### Secondary
- **Background Processing** - Parse large files asynchronously with progress indicators
- **Lazy Loading** - Load comments on-demand for visible regions only
- **Batch Operations** - Group multiple updates into single file write

---

## ‚ú® Features

### 1. AST Parse Cache

**Problem:**
Currently, every time a file is opened or a comment is added, we call VS Code's symbol provider which re-parses the entire AST. For a 2000-line file, this can take 100-300ms.

**Solution:**
Cache the AST symbol tree per file, invalidate only when file changes.

```typescript
// src/core/ASTCacheManager.ts
export interface ASTCacheEntry {
  documentUri: string;
  version: number;              // Document version number
  symbols: vscode.DocumentSymbol[];
  parsedAt: number;             // Timestamp
  parseTimeMs: number;          // How long it took
}

export class ASTCacheManager {
  private cache = new Map<string, ASTCacheEntry>();
  private readonly maxCacheSize = 50;  // Cache up to 50 files
  private readonly maxAge = 5 * 60 * 1000;  // 5 minutes

  /**
   * Get cached AST or parse if needed
   */
  async getSymbols(document: vscode.TextDocument): Promise<vscode.DocumentSymbol[]> {
    const key = document.uri.toString();
    const cached = this.cache.get(key);

    // Check if cache is valid
    if (cached && cached.version === document.version) {
      logger.debug(`AST cache HIT for ${document.fileName}`);
      return cached.symbols;
    }

    // Cache miss - parse AST
    logger.debug(`AST cache MISS for ${document.fileName}`);
    const startTime = Date.now();
    const symbols = await vscode.commands.executeCommand<vscode.DocumentSymbol[]>(
      'vscode.executeDocumentSymbolProvider',
      document.uri
    ) || [];
    const parseTimeMs = Date.now() - startTime;

    // Store in cache
    this.cache.set(key, {
      documentUri: key,
      version: document.version,
      symbols,
      parsedAt: Date.now(),
      parseTimeMs
    });

    // Evict old entries (LRU)
    if (this.cache.size > this.maxCacheSize) {
      this.evictOldest();
    }

    return symbols;
  }

  /**
   * Invalidate cache when document changes
   */
  invalidate(documentUri: vscode.Uri): void {
    this.cache.delete(documentUri.toString());
  }

  /**
   * Clear entire cache
   */
  clear(): void {
    this.cache.clear();
  }

  /**
   * Get cache statistics
   */
  getStats(): {hits: number, misses: number, hitRate: number} {
    // Track hits/misses for performance monitoring
  }

  private evictOldest(): void {
    // Find oldest entry by parsedAt timestamp
    // Delete from cache
  }
}
```

**Integration:**
- Wire ASTCacheManager into ASTAnchorManager
- Update all AST calls to use cache
- Invalidate on document change events

**Expected Performance:**
- First parse: 100-300ms (no change)
- Subsequent calls: <5ms (60-90x faster)
- Cache hit rate: >85% for active files

---

### 2. Comment File Cache

**Problem:**
Every comment operation loads the .comments file from disk using `fs.readFile`, which is slow for large comment files (>100KB).

**Solution:**
In-memory LRU cache with dirty bit tracking for write optimization.

```typescript
// src/io/CommentFileCache.ts
export interface CachedCommentFile {
  sourceUri: string;
  commentFile: CommentFile;
  version: number;              // Increments on each modification
  loadedAt: number;             // Timestamp
  isDirty: boolean;             // Has unsaved changes
  lastSavedAt: number;          // When last written to disk
}

export class CommentFileCache {
  private cache = new Map<string, CachedCommentFile>();
  private readonly maxCacheSize = 100;  // Cache up to 100 .comments files
  private readonly autoSaveDelay = 2000;  // Auto-save after 2s of inactivity
  private saveTimers = new Map<string, NodeJS.Timeout>();

  /**
   * Get comment file from cache or load from disk
   */
  async get(sourceUri: vscode.Uri): Promise<CommentFile> {
    const key = sourceUri.fsPath;
    const cached = this.cache.get(key);

    if (cached) {
      logger.debug(`Comment cache HIT for ${sourceUri.fsPath}`);
      return cached.commentFile;
    }

    // Cache miss - load from disk
    logger.debug(`Comment cache MISS for ${sourceUri.fsPath}`);
    const commentFile = await fileSystemManager.readCommentFile(sourceUri);

    if (commentFile) {
      this.cache.set(key, {
        sourceUri: key,
        commentFile,
        version: 1,
        loadedAt: Date.now(),
        isDirty: false,
        lastSavedAt: Date.now()
      });
    }

    return commentFile;
  }

  /**
   * Update comment file in cache (mark as dirty)
   */
  set(sourceUri: vscode.Uri, commentFile: CommentFile): void {
    const key = sourceUri.fsPath;
    const cached = this.cache.get(key);

    this.cache.set(key, {
      sourceUri: key,
      commentFile,
      version: (cached?.version || 0) + 1,
      loadedAt: cached?.loadedAt || Date.now(),
      isDirty: true,
      lastSavedAt: cached?.lastSavedAt || 0
    });

    // Schedule auto-save
    this.scheduleAutoSave(sourceUri);
  }

  /**
   * Flush dirty files to disk
   */
  async flush(sourceUri?: vscode.Uri): Promise<void> {
    if (sourceUri) {
      // Flush single file
      await this.flushFile(sourceUri);
    } else {
      // Flush all dirty files
      for (const [key, cached] of this.cache.entries()) {
        if (cached.isDirty) {
          await this.flushFile(vscode.Uri.file(key));
        }
      }
    }
  }

  private async flushFile(sourceUri: vscode.Uri): Promise<void> {
    const key = sourceUri.fsPath;
    const cached = this.cache.get(key);

    if (cached && cached.isDirty) {
      await fileSystemManager.writeCommentFile(sourceUri, cached.commentFile);
      cached.isDirty = false;
      cached.lastSavedAt = Date.now();
      logger.debug(`Flushed comment file ${sourceUri.fsPath}`);
    }
  }

  private scheduleAutoSave(sourceUri: vscode.Uri): void {
    const key = sourceUri.fsPath;

    // Clear existing timer
    const existingTimer = this.saveTimers.get(key);
    if (existingTimer) {
      clearTimeout(existingTimer);
    }

    // Schedule new save
    const timer = setTimeout(async () => {
      await this.flushFile(sourceUri);
      this.saveTimers.delete(key);
    }, this.autoSaveDelay);

    this.saveTimers.set(key, timer);
  }
}
```

**Integration:**
- Wire into CommentManager.loadComments()
- Update CommentManager.saveComments() to use cache.set() + flush()
- Flush on workspace save events

**Expected Performance:**
- First load: 10-50ms (disk read)
- Subsequent loads: <1ms (in-memory)
- Write batching: 5-10x fewer disk writes

---

### 3. Ghost Marker Verification Cache

**Problem:**
`GhostMarkerManager.verifyMarkers()` is called frequently and re-checks every marker even if code hasn't changed.

**Solution:**
Cache verification results per marker, invalidate only on line changes.

```typescript
// src/core/GhostMarkerCache.ts
export interface MarkerVerificationCache {
  markerId: string;
  documentVersion: number;      // Document version when verified
  lineHash: string;             // Hash of the line
  isValid: boolean;             // Verification result
  verifiedAt: number;           // Timestamp
}

export class GhostMarkerCache {
  private verificationCache = new Map<string, MarkerVerificationCache>();

  /**
   * Get cached verification result
   */
  getCachedVerification(
    markerId: string,
    document: vscode.TextDocument,
    currentLineHash: string
  ): boolean | null {
    const cached = this.verificationCache.get(markerId);

    if (cached &&
        cached.documentVersion === document.version &&
        cached.lineHash === currentLineHash) {
      return cached.isValid;
    }

    return null;  // Cache miss
  }

  /**
   * Store verification result
   */
  setCachedVerification(
    markerId: string,
    document: vscode.TextDocument,
    lineHash: string,
    isValid: boolean
  ): void {
    this.verificationCache.set(markerId, {
      markerId,
      documentVersion: document.version,
      lineHash,
      isValid,
      verifiedAt: Date.now()
    });
  }

  /**
   * Invalidate cache for specific marker
   */
  invalidate(markerId: string): void {
    this.verificationCache.delete(markerId);
  }

  /**
   * Invalidate all markers for a document
   */
  invalidateDocument(documentUri: vscode.Uri): void {
    // Clear all markers for this document
  }
}
```

**Expected Performance:**
- Verification with AST: 50-100ms per marker
- Verification with cache: <1ms per marker
- For 100 markers: 5000ms ‚Üí 100ms (50x faster)

---

### 4. Incremental Updates

**Problem:**
When a user types a single character, we re-verify ALL markers in the file.

**Solution:**
Only verify markers within changed line ranges + 10 line buffer.

```typescript
// src/core/IncrementalUpdateManager.ts
export class IncrementalUpdateManager {
  /**
   * Determine which markers need re-verification based on document changes
   */
  getAffectedMarkers(
    changes: readonly vscode.TextDocumentContentChangeEvent[],
    allMarkers: GhostMarker[]
  ): GhostMarker[] {
    const affectedLines = new Set<number>();

    // Collect all changed line ranges (with buffer)
    for (const change of changes) {
      const startLine = change.range.start.line;
      const endLine = change.range.end.line;

      // Add buffer of 10 lines before/after change
      for (let i = Math.max(0, startLine - 10); i <= endLine + 10; i++) {
        affectedLines.add(i);
      }
    }

    // Filter markers to only those on affected lines
    return allMarkers.filter(marker =>
      affectedLines.has(marker.line - 1)  // Convert to 0-indexed
    );
  }
}
```

**Expected Performance:**
- Small edit: Verify 2-5 markers instead of 100
- 95% reduction in verification work for typical edits

---

## üõ†Ô∏è Implementation Plan

### Phase 1: AST Cache (Day 1)
- [x] Create `src/core/ASTCacheManager.ts`
- [x] Implement LRU cache with version tracking
- [x] Wire into ASTAnchorManager.createAnchor()
- [x] Add cache invalidation on document change
- [x] Add statistics tracking (hits/misses)

### Phase 2: Comment File Cache (Day 2)
- [x] Create `src/io/CommentFileCache.ts`
- [x] Implement in-memory cache with dirty tracking
- [x] Add auto-save with debouncing
- [x] Wire into CommentManager
- [x] Add flush on workspace save

### Phase 3: Marker Verification Cache (Day 2-3)
- [x] Create `src/core/GhostMarkerCache.ts`
- [x] Wire into GhostMarkerManager.verifyMarkers()
- [x] Implement incremental update logic
- [x] Add performance metrics logging

### Phase 4: Background Processing (Day 3)
- [x] Add progress indicators for slow operations
- [x] Make large AST parses async with cancellation
- [x] Batch ghost marker updates

---

## üß™ Testing Strategy

### Performance Benchmarks
```typescript
// test/benchmark/CachePerformance.test.ts
describe('Performance Benchmarks', () => {
  it('should parse 1000-line file in <100ms (cached)', async () => {
    // First parse (cold cache)
    const start1 = Date.now();
    await astCache.getSymbols(document);
    const coldTime = Date.now() - start1;

    // Second parse (warm cache)
    const start2 = Date.now();
    await astCache.getSymbols(document);
    const warmTime = Date.now() - start2;

    expect(coldTime).to.be.lessThan(300);  // Cold: <300ms
    expect(warmTime).to.be.lessThan(5);    // Warm: <5ms
  });

  it('should verify 100 markers in <100ms (cached)', async () => {
    // Create 100 markers
    // Verify all (cold)
    // Verify all again (warm)
    // Warm should be <100ms
  });
});
```

### Integration Tests
```typescript
it('should maintain cache across file edits', async () => {
  // Load file into cache
  // Edit document
  // Verify cache invalidates
  // Re-load from cache
});

it('should auto-save after inactivity', async () => {
  // Mark file as dirty
  // Wait 2 seconds
  // Verify file flushed to disk
});
```

---

## üìä Success Metrics

| Operation | Before | After | Improvement |
|-----------|--------|-------|-------------|
| AST parse (warm) | 100-300ms | <5ms | 60-90x faster |
| Load .comments | 10-50ms | <1ms | 10-50x faster |
| Verify 100 markers | 5000ms | 100ms | 50x faster |
| Small edit verification | 100 markers | 2-5 markers | 95% reduction |

**Target Performance:**
- [ ] 1000-line file opens in <100ms
- [ ] Adding comment takes <50ms
- [ ] Typing doesn't cause lag (frame drops <5%)
- [ ] 100 comments load in <100ms
- [ ] Cache hit rate >80%

---

## üîó Dependencies

**Required:**
- Existing AST and Ghost Marker systems

**Optional:**
- IndexedDB for persistent cache (future: cache survives VS Code restart)

---

## üìù Documentation Needs

- [ ] Add "Performance" section to README
- [ ] Document cache configuration settings
- [ ] Add troubleshooting for cache issues
- [ ] Document cache statistics command
- [ ] Update CHANGELOG.md

---

## ‚öôÔ∏è Configuration

```json
{
  "pairedComments.performance.astCacheSize": 50,
  "pairedComments.performance.commentCacheSize": 100,
  "pairedComments.performance.autoSaveDelay": 2000,
  "pairedComments.performance.enableBackgroundParsing": true,
  "pairedComments.performance.incrementalUpdates": true
}
```

---

## üöÄ Future Enhancements (v2.2+)

- **Persistent Cache:** Store cache to disk, survive VS Code restarts
- **Worker Threads:** Offload AST parsing to worker thread (no UI blocking)
- **Predictive Pre-Loading:** Pre-load .comments for likely-to-open files
- **Compression:** Compress cached data to reduce memory footprint
- **Cache Warmup:** Pre-populate cache when workspace opens

---

**Status:** Design complete, ready for implementation
**Next Step:** Create `src/core/ASTCacheManager.ts` and begin Phase 1
